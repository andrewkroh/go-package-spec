// Code generated by cmd/gensql; DO NOT EDIT.

package pkgsql

// CREATE TABLE statements for each table.
const (
	fields                          = "CREATE TABLE IF NOT EXISTS fields (\n  -- Elasticsearch field definitions, flattened from nested YAML into dotted-path names.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  analyzer TEXT, -- Name of the analyzer to use for indexing. Unless search_analyzer is specified this analyzer is used for both indexing and searching. Only valid for 'type: text'.\n  copy_to TEXT, -- The copy_to parameter allows you to copy the values of multiple fields into a group field, which can then be queried as a single field.\n  date_format TEXT, -- The date format(s) that can be parsed. Type date format default to `strict_date_optional_time||epoch_millis`, see the [doc]. In JSON documents, dates are represented as strings. Elasticsearch uses ...\n  default_metric JSON, -- JSON-encoded DefaultMetric\n  description TEXT, -- Short description of field\n  dimension BOOLEAN, -- Declare a field as dimension of time series. This is attached to the field as a `time_series_dimension` mapping parameter.\n  doc_values BOOLEAN, -- Controls whether doc values are enabled for a field. All fields which support doc values have them enabled by default. If you are sure that you donâ€™t need to sort or aggregate on a field, or acce...\n  dynamic JSON, -- Dynamic controls whether new fields are added dynamically. Accepts true, false, \"strict\", or \"runtime\".\n  enabled BOOLEAN, -- The enabled setting, which can be applied only to the top-level mapping definition and to object fields, causes Elasticsearch to skip parsing of the contents of the field entirely. The JSON can sti...\n  example JSON, -- Example values for this field.\n  expected_values JSON, -- An array of expected values for the field. When defined, these are the only expected values.\n  external TEXT, -- External source reference\n  ignore_above INTEGER, -- Strings longer than the ignore_above setting will not be indexed or stored. For arrays of strings, ignore_above will be applied for each array element separately and string elements longer than ign...\n  ignore_malformed BOOLEAN, -- Trying to index the wrong data type into a field throws an exception by default, and rejects the whole document. The ignore_malformed parameter, if set to true, allows the exception to be ignored. ...\n  include_in_parent BOOLEAN, -- For nested field types, this specifies if all fields in the nested object are also added to the parent document as standard (flat) fields.\n  include_in_root BOOLEAN, -- For nested field types, this specifies if all fields in the nested object are also added to the root document as standard (flat) fields.\n  \"index\" BOOLEAN, -- The index option controls whether field values are indexed. Fields that are not indexed are typically not queryable.\n  inference_id TEXT, -- For semantic_text fields, this specifies the id of the inference endpoint associated with the field\n  metric_type TEXT, -- The metric type of a numeric field. This is attached to the field as a `time_series_metric` mapping parameter. A gauge is a single-value measurement that can go up or down over time, such as a temp...\n  metrics JSON, -- JSON-encoded Metrics\n  multi_fields JSON, -- It is often useful to index the same field in different ways for different purposes. This is the purpose of multi-fields. For instance, a string field could be mapped as a text field for full-text ...\n  name TEXT NOT NULL, -- Name of field. Names containing dots are automatically split into sub-fields. Names with wildcards generate dynamic mappings.\n  normalize JSON, -- Specifies the expected normalizations for a field. `array` normalization implies that the values in the field should always be an array, even if they are single values.\n  normalizer TEXT, -- Specifies the name of a normalizer to apply to keyword fields. A simple normalizer called lowercase ships with elasticsearch and can be used. Custom normalizers can be defined as part of analysis i...\n  null_value JSON, -- The null_value parameter allows you to replace explicit null values with the specified value so that it can be indexed and searched. A null value cannot be indexed or searched. When a field is set ...\n  object_type TEXT, -- Type of the members of the object when `type: object` is used. In these cases a dynamic template is created so direct subobjects of this field have the type indicated. When `object_type_mapping_typ...\n  object_type_mapping_type TEXT, -- Type that members of a field of with `type: object` must have in the source document. This type corresponds to the data type detected by the JSON parser, and is translated to the `match_mapping_typ...\n  path TEXT, -- For alias type fields this is the path to the target field. Note that this must be the full path, including any parent objects (e.g. object1.object2.field).\n  pattern TEXT, -- Regular expression pattern matching the allowed values for the field. This is used for development-time data validation.\n  runtime JSON, -- Runtime specifies if this field is evaluated at query time. Can be a boolean or a script string.\n  scaling_factor INTEGER, -- The scaling factor to use when encoding values. Values will be multiplied by this factor at index time and rounded to the closest long value. For instance, a scaled_float with a scaling_factor of 1...\n  search_analyzer TEXT, -- Name of the analyzer to use for searching. Only valid for 'type: text'.\n  store BOOLEAN, -- By default, field values are indexed, but not stored. This means that the field can be queried, but the original field cannot be retrieved. Setting this value to true ensures that the field is also...\n  subobjects BOOLEAN, -- Specifies if field names containing dots should be expanded into subobjects. For example, if this is set to `true`, a field named `foo.bar` will be expanded into an object with a field named `bar` ...\n  type TEXT, -- Datatype of field. If the type is set to object, a dynamic mapping is created. In this case, if the name doesn't contain any wildcard, the wildcard is added as the last segment of the path.\n  unit TEXT, -- Unit type to associate with a numeric field. This is attached to the field as metadata (via `meta`). By default, a field does not have a unit. The convention for percents is to use value 1 to mean ...\n  value TEXT, -- The value to associate with a constant_keyword field.\n  json_pointer TEXT -- JsonPointer is the RFC 6901 JSON Pointer to this field's location in the original fields file (e.g. /0/fields/1). Set by pkgreader after parsing.\n);\n"
	packages                        = "CREATE TABLE IF NOT EXISTS packages (\n  -- Fleet packages (integration, input, or content). Each row is one package version.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  agent_privileges_root BOOLEAN, -- whether collection requires root privileges in the agent\n  commit_id TEXT, -- git HEAD commit ID (populated when WithGitMetadata is used)\n  conditions_elastic_subscription TEXT, -- required Elastic subscription level\n  conditions_kibana_version TEXT, -- required Kibana version range\n  dir_name TEXT NOT NULL UNIQUE, -- directory name of the package\n  elasticsearch_privileges_cluster JSON, -- Elasticsearch cluster privilege requirements (JSON array)\n  policy_templates_behavior TEXT, -- behavior when multiple policy templates are defined (all, combined_policy, individual_policies)\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  description TEXT NOT NULL, -- Description\n  format_version TEXT NOT NULL, -- The version of the package specification format used by this package.\n  name TEXT NOT NULL, -- The name of the package.\n  owner_github TEXT NOT NULL, -- Github team name of the package maintainer.\n  owner_type TEXT NOT NULL, -- Describes who owns the package and the level of support that is provided. The 'elastic' value indicates that the package is built and maintained by Elastic. The 'partner' value indicates that the p...\n  source_license TEXT, -- Identifier of the license of the package, as specified in https://spdx.org/licenses/.\n  title TEXT NOT NULL, -- Title\n  type TEXT NOT NULL, -- The type of package.\n  version TEXT NOT NULL -- The version of the package.\n);\n"
	buildManifests                  = "CREATE TABLE IF NOT EXISTS build_manifests (\n  -- Build configuration for integration packages (_dev/build/build.yml).\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  dependencies_ecs_import_mappings BOOLEAN, -- Whether or not import common used dynamic templates and properties into the package\n  dependencies_ecs_reference TEXT NOT NULL -- Reference is the ECS version source reference. Values begin with \"git@\" (e.g. \"git@v8.11.0\").\n);\n"
	changelogs                      = "CREATE TABLE IF NOT EXISTS changelogs (\n  -- Changelog versions for a package. Each row is one version entry with its release date.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  version TEXT NOT NULL, -- Package version.\n  date TEXT -- Date is the approximate release date, populated via git blame when WithGitMetadata is used.\n);\n"
	changelogEntries                = "CREATE TABLE IF NOT EXISTS changelog_entries (\n  -- Individual changelog entries within a changelog version.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  changelogs_id INTEGER NOT NULL REFERENCES changelogs(id), -- foreign key to changelogs\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  description TEXT NOT NULL, -- Description of change.\n  link TEXT NOT NULL, -- Link to issue or PR describing change in detail.\n  type TEXT NOT NULL -- Type of change.\n);\n"
	dataStreams                     = "CREATE TABLE IF NOT EXISTS data_streams (\n  -- Data streams within integration packages. Each row is one data stream with its Elasticsearch and agent config.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  dir_name TEXT NOT NULL, -- directory name of the data stream\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  dataset TEXT, -- Name of data set.\n  dataset_is_prefix BOOLEAN, -- If true, the index pattern in the ES template will contain the dataset as a prefix only\n  elasticsearch_dynamic_dataset BOOLEAN, -- When set to true, agents running this integration are granted data stream privileges for all datasets of its type\n  elasticsearch_dynamic_namespace BOOLEAN, -- When set to true, agents running this integration are granted data stream privileges for all namespaces of its type\n  elasticsearch_index_mode TEXT, -- Elasticsearch.IndexMode\n  elasticsearch_index_template JSON, -- JSON-encoded IndexTemplate\n  elasticsearch_privileges JSON, -- Elasticsearch privilege requirements\n  elasticsearch_source_mode TEXT, -- Source mode to use. This configures how the document source (`_source`) is stored for this data stream. If configured as `default`, this mode is not configured and it uses Elasticsearch defaults. I...\n  hidden BOOLEAN, -- Specifies if a data stream is hidden, resulting in dot prefixed system indices. To set the data stream hidden without those dot prefixed indices, check `elasticsearch.index_template.data_stream.hid...\n  ilm_policy TEXT, -- The name of an existing ILM (Index Lifecycle Management) policy\n  \"release\" TEXT, -- Stability of data stream.\n  title TEXT NOT NULL, -- Title of data stream. It should include the source of the data that is being collected, and the kind of data collected such as logs or metrics. Words should be uppercased.\n  type TEXT, -- Type of data stream\n  github_code_owner TEXT -- GithubCodeOwner is the GitHub team code owner from CODEOWNERS, populated when WithCodeowners is used.\n);\n"
	agentTemplates                  = "CREATE TABLE IF NOT EXISTS agent_templates (\n  -- Agent Handlebars template files (.yml.hbs) from agent/ directories. Each row is one template file with its raw content. Referenced by streams, policy_templates, and policy_template_inputs via template_path.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  content TEXT NOT NULL, -- raw Handlebars template content\n  data_streams_id INTEGER REFERENCES data_streams(id), -- foreign key to data_streams (set for data stream templates, NULL for package-level)\n  file_path TEXT NOT NULL, -- file path relative to the package root (e.g. data_stream/logs/agent/stream/stream.yml.hbs)\n  packages_id INTEGER NOT NULL REFERENCES packages(id) -- foreign key to packages\n);\n"
	dataStreamFields                = "CREATE TABLE IF NOT EXISTS data_stream_fields (\n  -- Join table linking fields to data streams.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_stream_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  field_id INTEGER NOT NULL REFERENCES fields(id) -- foreign key to fields\n);\n"
	discoveryFields                 = "CREATE TABLE IF NOT EXISTS discovery_fields (\n  -- Fields associated with package discovery capabilities.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  name TEXT NOT NULL, -- name of the field\n  packages_id INTEGER NOT NULL REFERENCES packages(id) -- foreign key to packages\n);\n"
	docs                            = "CREATE TABLE IF NOT EXISTS docs (\n  -- Documentation files within packages. Content is optionally populated when WithDocContent is used.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  content TEXT, -- markdown content (NULL unless WithDocContent was used)\n  content_type TEXT NOT NULL, -- classification: readme, doc, or knowledge_base\n  file_path TEXT NOT NULL, -- file path relative to the package root (e.g. docs/README.md)\n  packages_id INTEGER NOT NULL REFERENCES packages(id) -- foreign key to packages\n);\n"
	images                          = "CREATE TABLE IF NOT EXISTS images (\n  -- Image files within packages (img/ directory). Join with icon/screenshot tables on src to correlate declared metadata with actual image properties.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  byte_size INTEGER NOT NULL, -- file size in bytes\n  height INTEGER, -- image height in pixels (NULL for SVG)\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  sha256 TEXT NOT NULL, -- hex-encoded SHA-256 hash of file contents\n  src TEXT NOT NULL, -- image path with leading slash to match icon/screenshot src (e.g. /img/icon.png)\n  width INTEGER -- image width in pixels (NULL for SVG)\n);\n"
	ingestPipelines                 = "CREATE TABLE IF NOT EXISTS ingest_pipelines (\n  -- Elasticsearch ingest pipeline definitions within data streams.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  file_name TEXT NOT NULL, -- file name of the pipeline (e.g. default.yml)\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  description TEXT -- Description of the pipeline.\n);\n"
	ingestProcessors                = "CREATE TABLE IF NOT EXISTS ingest_processors (\n  -- Individual ingest processors flattened from pipelines. Nested on_failure handlers are included as separate rows.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  ingest_pipelines_id INTEGER NOT NULL REFERENCES ingest_pipelines(id), -- foreign key to ingest_pipelines\n  attributes JSON, -- JSON-encoded processor attributes\n  json_pointer TEXT NOT NULL, -- RFC 6901 JSON Pointer location within the pipeline\n  ordinal INTEGER NOT NULL, -- order of processor within the pipeline\n  type TEXT NOT NULL, -- processor type (e.g. set, grok, rename)\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER -- source file column number\n);\n"
	kibanaSavedObjects              = "CREATE TABLE IF NOT EXISTS kibana_saved_objects (\n  -- Kibana saved objects (dashboards, visualizations, security rules, etc.) from the kibana/ directory. Each row is one JSON file.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  asset_type TEXT NOT NULL, -- asset type directory name (e.g. dashboard, visualization, security_rule)\n  core_migration_version TEXT, -- core Kibana migration version\n  description TEXT, -- description from attributes\n  file_path TEXT NOT NULL, -- file path relative to the package root\n  managed BOOLEAN, -- whether the object is managed by Kibana\n  object_id TEXT NOT NULL, -- unique identifier of the saved object\n  object_type TEXT, -- object type from JSON (e.g. dashboard, visualization, search)\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  reference_count INTEGER NOT NULL, -- number of references to other saved objects\n  title TEXT, -- human-readable title from attributes\n  type_migration_version TEXT -- type-specific migration version\n);\n"
	kibanaReferences                = "CREATE TABLE IF NOT EXISTS kibana_references (\n  -- References between Kibana saved objects. Each row is one reference from a saved object to another, enabling dependency graph queries.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  kibana_saved_objects_id INTEGER NOT NULL REFERENCES kibana_saved_objects(id), -- foreign key to kibana_saved_objects\n  ref_id TEXT NOT NULL, -- referenced object identifier\n  ref_name TEXT NOT NULL, -- reference name (e.g. panel_0, kibanaSavedObjectMeta.searchSourceJSON)\n  ref_type TEXT NOT NULL -- referenced object type (e.g. visualization, search, index-pattern)\n);\n"
	packageCategories               = "CREATE TABLE IF NOT EXISTS package_categories (\n  -- Categories assigned to a package.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  category TEXT NOT NULL, -- category value\n  package_id INTEGER NOT NULL REFERENCES packages(id) -- foreign key to packages\n);\n"
	packageFields                   = "CREATE TABLE IF NOT EXISTS package_fields (\n  -- Join table linking fields to packages (for input packages).\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  field_id INTEGER NOT NULL REFERENCES fields(id), -- foreign key to fields\n  package_id INTEGER NOT NULL REFERENCES packages(id) -- foreign key to packages\n);\n"
	packageIcons                    = "CREATE TABLE IF NOT EXISTS package_icons (\n  -- Icon definitions for a package.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  dark_mode BOOLEAN, -- Is this icon to be shown in dark mode?\n  size TEXT, -- Size of the icon.\n  src TEXT NOT NULL, -- Relative path to the icon's image file.\n  title TEXT, -- Title of icon.\n  type TEXT -- MIME type of the icon image file.\n);\n"
	packageScreenshots              = "CREATE TABLE IF NOT EXISTS package_screenshots (\n  -- Screenshot definitions for a package.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  size TEXT, -- Size of the screenshot.\n  src TEXT NOT NULL, -- Relative path to the screenshot's image file.\n  title TEXT NOT NULL, -- Title of screenshot.\n  type TEXT -- MIME type of the screenshot image file.\n);\n"
	pipelineTests                   = "CREATE TABLE IF NOT EXISTS pipeline_tests (\n  -- Pipeline test cases for data streams. Each row is one test event file with optional per-case config.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  config_path TEXT, -- path to per-case config file\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  dynamic_fields JSON, -- dynamic fields with regex patterns (from per-case config)\n  event_path TEXT NOT NULL, -- path to event file\n  expected_path TEXT, -- path to expected output file\n  fields JSON, -- field definitions (from per-case config)\n  format TEXT NOT NULL, -- event file format (json or raw)\n  multiline JSON, -- multi-line configuration (from per-case raw config)\n  name TEXT NOT NULL, -- test case stem name (e.g. test-example)\n  numeric_keyword_fields JSON, -- keyword fields allowed numeric values (from per-case config)\n  skip_link TEXT, -- link to issue for skipped test (from per-case config)\n  skip_reason TEXT, -- reason test is skipped (from per-case config)\n  string_number_fields JSON -- numeric fields allowed string values (from per-case config)\n);\n"
	policyTemplates                 = "CREATE TABLE IF NOT EXISTS policy_templates (\n  -- Policy templates offered by integration and input packages. Defines how a package is configured in Fleet.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  dynamic_signal_types BOOLEAN, -- whether transforms and index templates are created based on pipeline config (input packages only)\n  input TEXT, -- input type for input packages (e.g. cel, httpjson)\n  policy_template_type TEXT, -- data stream type for input packages (logs, metrics, synthetics, traces)\n  template_path TEXT, -- Resolved file path to the agent template relative to the package root (e.g. agent/input/input.yml.hbs). Only set for input packages. Joinable directly to agent_templates.file_path.\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  configuration_links JSON, -- JSON-encoded ConfigurationLinks\n  data_streams JSON, -- List of data streams compatible with the policy template.\n  deployment_modes_agentless_division TEXT, -- The division responsible for the integration. This is used to tag the agentless agent deployments for monitoring.\n  deployment_modes_agentless_enabled BOOLEAN, -- Indicates if the agentless deployment mode is available for this template policy. It is disabled by default.\n  deployment_modes_agentless_is_default BOOLEAN, -- On policy templates that support multiple deployment modes, this setting can be set to true to use agentless mode by default.\n  deployment_modes_agentless_organization TEXT, -- The responsible organization of the integration. This is used to tag the agentless agent deployments for monitoring.\n  deployment_modes_agentless_resources_requests_cpu TEXT, -- The amount of CPUs that the Agentless deployment will be initially allocated.\n  deployment_modes_agentless_resources_requests_memory TEXT, -- The amount of memory that the Agentless deployment will be initially allocated.\n  deployment_modes_agentless_team TEXT, -- The team responsible for the integration. This is used to tag the agentless agent deployments for monitoring.\n  deployment_modes_default_enabled BOOLEAN, -- Indicates if the default deployment mode is available for this template policy. It is enabled by default.\n  description TEXT NOT NULL, -- Longer description of policy template.\n  fips_compatible BOOLEAN, -- FipsCompatible\n  multiple BOOLEAN, -- Multiple\n  name TEXT NOT NULL, -- Name of policy template.\n  title TEXT NOT NULL -- Title of policy template.\n);\n"
	policyTemplateCategories        = "CREATE TABLE IF NOT EXISTS policy_template_categories (\n  -- Categories assigned to a policy template.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  category TEXT NOT NULL, -- category value\n  policy_template_id INTEGER NOT NULL REFERENCES policy_templates(id) -- foreign key to policy_templates\n);\n"
	policyTemplateIcons             = "CREATE TABLE IF NOT EXISTS policy_template_icons (\n  -- Icon definitions for a policy template.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  policy_templates_id INTEGER NOT NULL REFERENCES policy_templates(id), -- foreign key to policy_templates\n  dark_mode BOOLEAN, -- Is this icon to be shown in dark mode?\n  size TEXT, -- Size of the icon.\n  src TEXT NOT NULL, -- Relative path to the icon's image file.\n  title TEXT, -- Title of icon.\n  type TEXT -- MIME type of the icon image file.\n);\n"
	policyTemplateInputs            = "CREATE TABLE IF NOT EXISTS policy_template_inputs (\n  -- Inputs defined within a policy template.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  policy_templates_id INTEGER NOT NULL REFERENCES policy_templates(id), -- foreign key to policy_templates\n  deployment_modes JSON, -- List of deployment modes that this input is compatible with. If not specified, the input is compatible with all deployment modes.\n  description TEXT NOT NULL, -- Longer description of input.\n  hide_in_var_group_options JSON, -- HideInVarGroupOptions filters out specific var_group options for this input.\n  input_group TEXT, -- Name of the input group\n  multi BOOLEAN, -- Can input be defined multiple times\n  template_path TEXT, -- Resolved file path to the agent template relative to the package root (e.g. agent/input/httpjson.yml.hbs). NULL when not specified. Joinable directly to agent_templates.file_path.\n  title TEXT NOT NULL, -- Title of input.\n  type TEXT NOT NULL -- Type of input.\n);\n"
	policyTemplateScreenshots       = "CREATE TABLE IF NOT EXISTS policy_template_screenshots (\n  -- Screenshot definitions for a policy template.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  policy_templates_id INTEGER NOT NULL REFERENCES policy_templates(id), -- foreign key to policy_templates\n  size TEXT, -- Size of the screenshot.\n  src TEXT NOT NULL, -- Relative path to the screenshot's image file.\n  title TEXT NOT NULL, -- Title of screenshot.\n  type TEXT -- MIME type of the screenshot image file.\n);\n"
	policyTests                     = "CREATE TABLE IF NOT EXISTS policy_tests (\n  -- Policy test cases for data streams and input packages.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  case_name TEXT NOT NULL, -- test case name extracted from filename\n  data_streams_id INTEGER REFERENCES data_streams(id), -- foreign key to data_streams (set for integration packages)\n  packages_id INTEGER REFERENCES packages(id), -- foreign key to packages (set for input packages)\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  data_stream JSON, -- Configuration for the data stream.\n  input TEXT, -- The input of the package to test.\n  skip_link TEXT NOT NULL, -- Link to issue with more details about skipped test or to track re-enabling skipped test.\n  skip_reason TEXT NOT NULL, -- Short explanation for why test has been skipped.\n  vars JSON -- Variables used to configure settings defined in the package manifest.\n);\n"
	routingRules                    = "CREATE TABLE IF NOT EXISTS routing_rules (\n  -- Routing rules for rerouting documents from a source dataset (technical preview).\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  \"if\" TEXT NOT NULL, -- Conditionally execute the processor\n  namespace JSON, -- Namespace is the field reference or static value for the namespace part of the data stream name.\n  target_dataset JSON -- TargetDataset is the field reference or static value for the dataset part of the data stream name.\n);\n"
	sampleEvents                    = "CREATE TABLE IF NOT EXISTS sample_events (\n  -- Sample event data for data streams.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  event JSON NOT NULL -- sample event data (JSON)\n);\n"
	securityRules                   = "CREATE TABLE IF NOT EXISTS security_rules (\n  -- Security detection rule attributes extracted from Kibana saved objects of type security_rule. Has a 1:1 relationship with kibana_saved_objects. Title and description are on the parent table.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  anomaly_threshold INTEGER, -- anomaly score threshold for machine_learning rules\n  author JSON, -- rule authors (JSON array of strings)\n  building_block_type TEXT, -- building block type when rule is a building block\n  enabled BOOLEAN, -- whether the rule is enabled by default\n  false_positives JSON, -- known false positive scenarios (JSON array of strings)\n  from_time TEXT, -- time range start for query (e.g. now-9m). Named from_time because FROM is reserved.\n  interval TEXT, -- check interval (e.g. 5m)\n  kibana_saved_objects_id INTEGER NOT NULL REFERENCES kibana_saved_objects(id), -- foreign key to kibana_saved_objects\n  language TEXT, -- query language: kuery, eql, esql, lucene\n  license TEXT, -- rule license (e.g. Elastic License v2)\n  machine_learning_job_id JSON, -- ML job identifier(s) for machine_learning rules (JSON string or array)\n  max_signals INTEGER, -- maximum alerts per execution\n  new_terms_fields JSON, -- fields for new_terms rules (JSON array)\n  new_terms_history_window_start TEXT, -- history window start for new_terms rules\n  note TEXT, -- markdown investigation/triage guide\n  \"query\" TEXT, -- detection query text (EQL, KQL, ESQL, or Lucene)\n  \"references\" JSON, -- external reference URLs (JSON array of strings)\n  risk_score REAL, -- numeric risk score (0-100)\n  risk_score_mapping JSON, -- risk score mapping configuration (JSON array)\n  rule_id TEXT NOT NULL, -- unique rule identifier (attributes.rule_id)\n  rule_name_override TEXT, -- field name used to override the rule name in alerts\n  setup TEXT, -- markdown setup instructions\n  severity TEXT, -- severity level: low, medium, high, critical\n  severity_mapping JSON, -- severity mapping configuration (JSON array)\n  threat_index JSON, -- threat indicator indices for threat_match rules (JSON array)\n  threat_indicator_path TEXT, -- path to threat indicator field for threat_match rules\n  threat_mapping JSON, -- threat indicator field mappings for threat_match rules (JSON array)\n  threat_query TEXT, -- threat indicator query for threat_match rules\n  threshold JSON, -- threshold configuration for threshold rules (JSON object)\n  timestamp_override TEXT, -- field name used to override @timestamp for rule execution\n  type TEXT, -- rule type: eql, query, new_terms, esql, machine_learning, threshold, threat_match\n  version INTEGER -- rule version number\n);\n"
	securityRuleIndexPatterns       = "CREATE TABLE IF NOT EXISTS security_rule_index_patterns (\n  -- Elasticsearch index patterns monitored by a security rule. Enables queries like \"which rules monitor logs-okta*?\"\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  pattern TEXT NOT NULL, -- index pattern (e.g. logs-endpoint.events.*, endgame-*)\n  security_rules_id INTEGER NOT NULL REFERENCES security_rules(id) -- foreign key to security_rules\n);\n"
	securityRuleRelatedIntegrations = "CREATE TABLE IF NOT EXISTS security_rule_related_integrations (\n  -- Integrations related to a security rule. Enables queries like \"which rules relate to the okta integration?\"\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  integration TEXT, -- specific integration within the package\n  package TEXT NOT NULL, -- integration package name (e.g. endpoint, okta)\n  security_rules_id INTEGER NOT NULL REFERENCES security_rules(id), -- foreign key to security_rules\n  version TEXT -- required version range (e.g. ^8.2.0)\n);\n"
	securityRuleRequiredFields      = "CREATE TABLE IF NOT EXISTS security_rule_required_fields (\n  -- Fields required by a security rule. Enables queries like \"which rules depend on event.kind?\"\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  ecs BOOLEAN, -- whether the field is from ECS\n  name TEXT NOT NULL, -- field name (e.g. event.action, process.name)\n  security_rules_id INTEGER NOT NULL REFERENCES security_rules(id), -- foreign key to security_rules\n  type TEXT -- field type (e.g. keyword, long)\n);\n"
	securityRuleTags                = "CREATE TABLE IF NOT EXISTS security_rule_tags (\n  -- Tags assigned to a security rule. Tags use a structured convention like \"Domain: Endpoint\", \"OS: Windows\", \"Tactic: Defense Evasion\", \"Data Source: Elastic Defend\".\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  security_rules_id INTEGER NOT NULL REFERENCES security_rules(id), -- foreign key to security_rules\n  tag TEXT NOT NULL -- tag value (e.g. 'Domain: Endpoint', 'Tactic: Defense Evasion')\n);\n"
	securityRuleThreats             = "CREATE TABLE IF NOT EXISTS security_rule_threats (\n  -- MITRE ATT&CK threat mappings for security rules. Each row is one tactic+technique pair. A tactic with 3 techniques produces 3 rows. A tactic with no techniques produces 1 row with NULL technique columns. Subtechniques are stored as JSON.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  security_rules_id INTEGER NOT NULL REFERENCES security_rules(id), -- foreign key to security_rules\n  subtechniques JSON, -- subtechnique array [{id, name, reference}] (JSON)\n  tactic_id TEXT NOT NULL, -- MITRE ATT&CK tactic ID (e.g. TA0005)\n  tactic_name TEXT NOT NULL, -- MITRE ATT&CK tactic name (e.g. Defense Evasion)\n  technique_id TEXT, -- MITRE ATT&CK technique ID (e.g. T1036)\n  technique_name TEXT -- MITRE ATT&CK technique name (e.g. Masquerading)\n);\n"
	staticTests                     = "CREATE TABLE IF NOT EXISTS static_tests (\n  -- Static test cases for data streams.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  case_name TEXT NOT NULL, -- test case name extracted from filename\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  skip_link TEXT NOT NULL, -- Link to issue with more details about skipped test or to track re-enabling skipped test.\n  skip_reason TEXT NOT NULL -- Short explanation for why test has been skipped.\n);\n"
	streams                         = "CREATE TABLE IF NOT EXISTS streams (\n  -- Streams offered by a data stream.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_streams_id INTEGER NOT NULL REFERENCES data_streams(id), -- foreign key to data_streams\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  description TEXT NOT NULL, -- Description of the stream. It should describe what is being collected and with what collector, following the structure \"Collect X from Y with X\".\n  enabled BOOLEAN, -- Is stream enabled?\n  input TEXT NOT NULL, -- Input\n  template_path TEXT, -- Resolved file path to the agent template relative to the package root (e.g. data_stream/logs/agent/stream/stream.yml.hbs). Defaults to stream.yml.hbs when not specified in the manifest. Joinable directly to agent_templates.file_path.\n  title TEXT NOT NULL -- Title of the stream. It should include the source of the data that is being collected, and the kind of data collected such as logs or metrics. Words should be uppercased.\n);\n"
	systemTests                     = "CREATE TABLE IF NOT EXISTS system_tests (\n  -- System test cases for data streams and input packages.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  case_name TEXT NOT NULL, -- test case name extracted from filename\n  data_streams_id INTEGER REFERENCES data_streams(id), -- foreign key to data_streams (set for integration packages)\n  packages_id INTEGER REFERENCES packages(id), -- foreign key to packages (set for input packages)\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  agent_base_image TEXT, -- Elastic Agent image to be used for testing. Setting `default` will be used the same Elastic Agent image as the stack. Setting `systemd` will use the image containing all the binaries for running Be...\n  agent_linux_capabilities JSON, -- Linux Capabilities that must been enabled in the system to run the Elastic Agent process\n  agent_pid_mode TEXT, -- Control access to PID namespaces. When set to `host`, the Elastic Agent will have access to the PID namespace of the host.\n  agent_ports JSON, -- List of ports to be exposed to access to the Elastic Agent\n  agent_pre_start_script_contents TEXT NOT NULL, -- Code to run before starting the Elastic Agent.\n  agent_pre_start_script_language TEXT, -- Programming language of the pre-start script. Currently, only \"sh\" is supported.\n  agent_provisioning_script_contents TEXT NOT NULL, -- Code to run as a provisioning script.\n  agent_provisioning_script_language TEXT, -- Programming language of the provisioning script.\n  agent_runtime TEXT, -- Runtime to run the Elastic Agent process\n  agent_user TEXT, -- User that runs the Elastic Agent process\n  data_stream JSON, -- JSON-encoded DataStream\n  skip_link TEXT NOT NULL, -- Link to issue with more details about skipped test or to track re-enabling skipped test.\n  skip_reason TEXT NOT NULL, -- Short explanation for why test has been skipped.\n  skip_ignored_fields JSON, -- If listed here, elastic-package system tests will not fail if values for the specified field names can't be indexed for any incoming documents. This should only be used if the failure is related to...\n  vars JSON, -- Variables used to configure settings defined in the package manifest.\n  wait_for_data_timeout TEXT -- Timeout for waiting for metrics data during a system test.\n);\n"
	tags                            = "CREATE TABLE IF NOT EXISTS tags (\n  -- Kibana tags associated with integration packages.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  asset_ids JSON, -- Asset IDs where this tag is going to be added. If two or more pacakges define the same tag, there will be just one tag created in Kibana and all the assets will be using the same tag.\n  asset_types JSON, -- This tag will be added to all the assets of these types included in the package. If two or more pacakges define the same tag, there will be just one tag created in Kibana and all the assets will be...\n  text TEXT -- Tag name.\n);\n"
	transforms                      = "CREATE TABLE IF NOT EXISTS transforms (\n  -- Elasticsearch transform configurations within integration packages.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  packages_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  dir_name TEXT NOT NULL, -- directory name of the transform\n  manifest_destination_index_template JSON, -- Elasticsearch index template for the transform destination (JSON)\n  manifest_start BOOLEAN, -- whether to start the transform upon installation\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  meta JSON, -- Meta holds user-defined metadata about the transform.\n  description TEXT, -- Description\n  dest JSON, -- JSON-encoded Dest\n  frequency TEXT, -- Frequency\n  latest JSON, -- JSON-encoded Latest\n  pivot JSON, -- JSON-encoded Pivot\n  retention_policy JSON, -- JSON-encoded RetentionPolicy\n  settings JSON, -- JSON-encoded Settings\n  source JSON, -- JSON-encoded Source\n  sync JSON -- JSON-encoded Sync\n);\n"
	transformFields                 = "CREATE TABLE IF NOT EXISTS transform_fields (\n  -- Join table linking fields to transforms.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  field_id INTEGER NOT NULL REFERENCES fields(id), -- foreign key to fields\n  transform_id INTEGER NOT NULL REFERENCES transforms(id) -- foreign key to transforms\n);\n"
	vars                            = "CREATE TABLE IF NOT EXISTS vars (\n  -- Input variable definitions. Linked to packages, policy templates, streams, or inputs via join tables.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  file_path TEXT, -- source file path\n  file_line INTEGER, -- source file line number\n  file_column INTEGER, -- source file column number\n  \"default\" JSON, -- Default is the default value for the variable.\n  description TEXT, -- Short description of variable.\n  hide_in_deployment_modes JSON, -- Whether this variable should be hidden in the UI for agent policies intended to some specific deployment modes.\n  max_duration TEXT, -- The maximum allowed duration value for duration data types. This property can only be used when the type is set to 'duration'.\n  min_duration TEXT, -- The minimum allowed duration value for duration data types. This property can only be used when the type is set to 'duration'.\n  multi BOOLEAN, -- Can variable contain multiple values?\n  name TEXT NOT NULL, -- Variable name.\n  options JSON, -- Options provides the list of selectable options when type is \"select\".\n  required BOOLEAN, -- Is variable required?\n  secret BOOLEAN, -- Specifying that a variable is secret means that Kibana will store the value separate from the package policy in a more secure index. This is useful for passwords and other sensitive information. On...\n  show_user BOOLEAN, -- Should this variable be shown to the user by default?\n  title TEXT, -- Title of variable.\n  type TEXT NOT NULL, -- Data type of variable. A duration type is a sequence of decimal numbers, each with a unit suffix, such as \"60s\", \"1m\" or \"2h45m\". Duration values must follow these rules: - Use time units of \"ms\", ...\n  url_allowed_schemes JSON -- List of allowed URL schemes for the url type. If empty, any scheme is allowed. An empty string can be used to indicate that the scheme is not mandatory.\n);\n"
	deprecations                    = "CREATE TABLE IF NOT EXISTS deprecations (\n  -- Deprecation notices for packages, policy templates, inputs, data streams, and vars. Each row links to exactly one parent entity via a nullable FK.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  data_streams_id INTEGER REFERENCES data_streams(id), -- foreign key to data_streams (set when a data stream is deprecated)\n  description TEXT NOT NULL, -- reason for deprecation\n  packages_id INTEGER REFERENCES packages(id), -- foreign key to packages (set when a package is deprecated)\n  policy_template_inputs_id INTEGER REFERENCES policy_template_inputs(id), -- foreign key to policy_template_inputs (set when an input is deprecated)\n  policy_templates_id INTEGER REFERENCES policy_templates(id), -- foreign key to policy_templates (set when a policy template is deprecated)\n  replaced_by_data_stream TEXT, -- name of the data stream that replaces the deprecated one\n  replaced_by_input TEXT, -- name of the input that replaces the deprecated one\n  replaced_by_package TEXT, -- name of the package that replaces the deprecated one\n  replaced_by_policy_template TEXT, -- name of the policy template that replaces the deprecated one\n  replaced_by_variable TEXT, -- name of the variable that replaces the deprecated one\n  since TEXT NOT NULL, -- version since when deprecated\n  vars_id INTEGER REFERENCES vars(id) -- foreign key to vars (set when a var is deprecated)\n);\n"
	packageVars                     = "CREATE TABLE IF NOT EXISTS package_vars (\n  -- Join table linking vars to packages.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  package_id INTEGER NOT NULL REFERENCES packages(id), -- foreign key to packages\n  var_id INTEGER NOT NULL REFERENCES vars(id) -- foreign key to vars\n);\n"
	policyTemplateInputVars         = "CREATE TABLE IF NOT EXISTS policy_template_input_vars (\n  -- Join table linking vars to policy template inputs.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  policy_template_input_id INTEGER NOT NULL REFERENCES policy_template_inputs(id), -- foreign key to policy_template_inputs\n  var_id INTEGER NOT NULL REFERENCES vars(id) -- foreign key to vars\n);\n"
	policyTemplateVars              = "CREATE TABLE IF NOT EXISTS policy_template_vars (\n  -- Join table linking vars to policy templates.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  policy_template_id INTEGER NOT NULL REFERENCES policy_templates(id), -- foreign key to policy_templates\n  var_id INTEGER NOT NULL REFERENCES vars(id) -- foreign key to vars\n);\n"
	streamVars                      = "CREATE TABLE IF NOT EXISTS stream_vars (\n  -- Join table linking vars to streams.\n  id INTEGER PRIMARY KEY AUTOINCREMENT, -- unique identifier\n  stream_id INTEGER NOT NULL REFERENCES streams(id), -- foreign key to streams\n  var_id INTEGER NOT NULL REFERENCES vars(id) -- foreign key to vars\n);\n"
)

// creates contains all CREATE TABLE statements in dependency order.
var creates = []string{fields, packages, buildManifests, changelogs, changelogEntries, dataStreams, agentTemplates, dataStreamFields, discoveryFields, docs, images, ingestPipelines, ingestProcessors, kibanaSavedObjects, kibanaReferences, packageCategories, packageFields, packageIcons, packageScreenshots, pipelineTests, policyTemplates, policyTemplateCategories, policyTemplateIcons, policyTemplateInputs, policyTemplateScreenshots, policyTests, routingRules, sampleEvents, securityRules, securityRuleIndexPatterns, securityRuleRelatedIntegrations, securityRuleRequiredFields, securityRuleTags, securityRuleThreats, staticTests, streams, systemTests, tags, transforms, transformFields, vars, deprecations, packageVars, policyTemplateInputVars, policyTemplateVars, streamVars}
